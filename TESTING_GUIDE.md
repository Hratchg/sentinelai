# SentinelAI Testing Guide - Phase 1 & Phase 2

## ğŸ¯ What We're Testing

âœ… **Phase 1**: Voice activation with "Hey Sentinel" wake word
âœ… **Phase 2**: Real AI responses using Claude API (or stub mode)

---

## ğŸ“‹ Pre-Test Checklist

### 1. Environment Setup

**Check `.env` file** (`backend/.env`):
```bash
# For Phase 1 only (stub mode):
CAMERA_IDS=0
VOICE_ENABLED=true

# For Phase 2 (real AI):
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx  # Uncomment and add your key
```

**Get Anthropic API Key** (for Phase 2):
1. Visit: https://console.anthropic.com/
2. Sign in or create account
3. Go to "API Keys" â†’ "Create Key"
4. Copy key and add to `.env`

### 2. Browser Requirements

âœ… **Recommended**: Chrome or Edge
âš ï¸ **Limited Support**: Safari
âŒ **Not Supported**: Firefox (Web Speech API issues)

### 3. Microphone Permissions

Make sure your microphone is:
- âœ… Connected and working
- âœ… Not muted
- âœ… Set as default device (optional)

---

## ğŸš€ Starting the System

### Terminal 1: Backend

```powershell
cd C:\Users\hratc\sentinelai
python run.py
```

**Expected Output:**
```
INFO - Starting SentinelAI API server...
INFO - Database initialized successfully
INFO - Real-time pipeline initialized
INFO - Camera streams started: [0]
INFO - Application startup complete
INFO - Uvicorn running on http://0.0.0.0:8000
```

**Troubleshooting**:
- âŒ `ModuleNotFoundError`: Run `pip install -r requirements.txt`
- âŒ `Camera failed`: Check if webcam is in use by another app
- âŒ `Port 8000 in use`: Close other apps using port 8000

### Terminal 2: Frontend

```powershell
cd C:\Users\hratc\sentinelai\frontend
npm run dev
```

**Expected Output:**
```
VITE v5.x.x  ready in xxx ms

âœ  Local:   http://localhost:5173/
âœ  Network: use --host to expose
```

**Troubleshooting**:
- âŒ `npm: command not found`: Install Node.js from https://nodejs.org/
- âŒ `Dependencies not found`: Run `npm install`
- âŒ `Port 5173 in use`: Close other apps or use different port

---

## ğŸ§ª Test Scenarios

### Test 1: Login & Dashboard Access

**Steps**:
1. Open browser: `http://localhost:5173`
2. You should see login page
3. If no account exists, click "Register"
4. Register with:
   - Username: `testuser`
   - Email: `test@example.com`
   - Password: `password123`
5. Should redirect to dashboard

**Expected Result**:
- âœ… Dashboard loads with dark theme
- âœ… Left side: Live camera feed
- âœ… Right side: Chat interface with AI Assistant header
- âœ… Bottom-right: Voice Control component (microphone button)

**Troubleshooting**:
- âŒ Blank page: Check browser console (F12) for errors
- âŒ Login fails: Check backend is running on port 8000
- âŒ 404 errors: Verify both frontend and backend are running

---

### Test 2: Voice Control Activation (Phase 1)

**Steps**:
1. Click the **microphone icon** in bottom-right
2. Browser should prompt for microphone permission
3. Click **Allow**
4. Component should show:
   - Green pulsing dot
   - "Say 'Hey Sentinel' to activate"
   - Audio waveform animation

**Expected Result**:
- âœ… Microphone button turns red (recording)
- âœ… Waveform shows audio levels
- âœ… Status shows "Say 'Hey Sentinel' to activate"

**Troubleshooting**:
- âŒ "Voice control unavailable": Browser doesn't support Web Speech API
- âŒ "Microphone access denied": Check browser permissions
- âŒ No waveform: Check microphone is not muted

---

### Test 3: Wake Word Detection (Phase 1)

**Steps**:
1. With voice control active, say clearly: **"Hey Sentinel"**
2. Wait 1-2 seconds

**Expected Result**:
- âœ… Waveform turns **blue** (wake word detected)
- âœ… Status changes to "Listening for command..."
- âœ… Blue pulsing indicator appears

**Troubleshooting**:
- âŒ No detection: Speak louder or closer to microphone
- âŒ False positives: Adjust `WAKE_WORD_SENSITIVITY` in `.env` (lower = less sensitive)
- âŒ Audio level too low: Check microphone volume settings

---

### Test 4: Voice Command (Phase 1 - Stub Mode)

**Prerequisites**: No `ANTHROPIC_API_KEY` in `.env` (stub mode)

**Steps**:
1. Say: **"Hey Sentinel, who is on camera 1?"**
2. Wait for response

**Expected Result**:
- âœ… Question appears in chat (user message, blue bubble)
- âœ… AI response appears (assistant message, dark gray bubble)
- âœ… Response says: "I received your question: 'who is on camera 1?'. Voice command system is working! Full LLM integration with Claude API will be implemented in Phase 2..."

**Troubleshooting**:
- âŒ No response: Check WebSocket connection in browser console
- âŒ Connection error: Verify backend is running and JWT token is valid
- âŒ Error message: Check backend logs for errors

---

### Test 5: Voice Command (Phase 2 - Real AI)

**Prerequisites**: `ANTHROPIC_API_KEY` is set in `.env`

**Steps**:
1. Restart backend (if running): `Ctrl+C` then `python run.py`
2. Say: **"Hey Sentinel, who is on camera 1?"**
3. Wait for AI response (may take 2-5 seconds)

**Expected Result** (Empty Database):
```
AI: "System Status: No persons detected yet. Monitoring is active."
```

**Expected Result** (With Data):
```
AI: "I can see 2 people in the system:
     1. John Smith - last seen 5 minutes ago
     2. Sarah Johnson - last seen 2 hours ago"
     [Video clips may appear if available]
```

**Troubleshooting**:
- âŒ "Invalid API key": Check key in `.env` is correct
- âŒ API errors: Check https://status.anthropic.com/
- âŒ Slow responses: Normal for first request (model cold start)

---

### Test 6: Typed Chat (Phase 2)

**Steps**:
1. In the chat input box (bottom of right panel)
2. Type: **"Who is on camera 1?"**
3. Click **Send** or press **Enter**

**Expected Result**:
- âœ… Loading indicator (3 bouncing dots)
- âœ… AI response appears after 2-5 seconds
- âœ… Response is contextually relevant
- âœ… Timestamp shows below message

**Troubleshooting**:
- âŒ No response: Check backend logs for errors
- âŒ Error message: Likely API issue or database error

---

### Test 7: Video Clip Display (Phase 2)

**Note**: Only works if video clips exist in database

**Steps**:
1. Ask a question that should return clips: **"Show me recent activity"**
2. Wait for response

**Expected Result**:
- âœ… AI response includes video player(s)
- âœ… Video controls (play, pause, seek)
- âœ… Clip metadata below video (person name, event type, timestamp)

**Troubleshooting**:
- âŒ No clips: Database is empty (normal for new installation)
- âŒ Video won't play: Check clip file path in database
- âŒ 404 error: Clip file doesn't exist on disk

---

### Test 8: Multiple Conversations (Phase 2)

**Steps**:
1. Ask: **"Hey Sentinel, who is on camera 1?"**
2. Wait for response
3. Ask: **"When did I last see anyone?"**
4. Wait for response
5. Type in chat: **"What gestures have been detected?"**

**Expected Result**:
- âœ… All messages appear in chronological order
- âœ… Each response is relevant to its question
- âœ… Chat scrolls to bottom automatically
- âœ… Up to 10 voice responses stored

**Troubleshooting**:
- âŒ Out of order: Check timestamps
- âŒ Duplicate responses: May be a rendering issue, refresh page

---

### Test 9: WebSocket Reconnection (Phase 1)

**Steps**:
1. Stop the backend (`Ctrl+C`)
2. Observe frontend (camera feed should show "Disconnected")
3. Restart backend (`python run.py`)
4. Wait 3 seconds

**Expected Result**:
- âœ… Frontend automatically reconnects
- âœ… Status changes to "Connected"
- âœ… Camera feed resumes (if camera stream works)

**Troubleshooting**:
- âŒ No reconnection: Check browser console for errors
- âŒ Connection loop: Backend may be crashing, check logs

---

### Test 10: Multi-User Isolation (Phase 1 & 2)

**Steps**:
1. Open browser in **incognito/private mode**
2. Login with a **different account**
3. Ask a question in both windows

**Expected Result**:
- âœ… Each user sees only their own conversations
- âœ… No cross-user data leakage
- âœ… Separate WebSocket connections for each user

**Troubleshooting**:
- âŒ Shared data: Critical security issue, check JWT implementation

---

## ğŸ“Š Performance Benchmarks

### Expected Metrics:

| Metric | Phase 1 (Stub) | Phase 2 (Real AI) |
|--------|----------------|-------------------|
| Wake word detection | < 1 second | < 1 second |
| Voice â†’ Response | 1-2 seconds | 3-7 seconds |
| Typed â†’ Response | < 1 second | 2-5 seconds |
| WebSocket latency | < 100ms | < 100ms |
| Video frame rate | 15-30 FPS | 15-30 FPS |

### Performance Issues:

**Slow Responses**:
- Check network connection
- Check API status (Phase 2)
- Check CPU usage (high load may slow camera processing)

**High Latency**:
- Check WebSocket connection quality
- Try using localhost instead of network IP

---

## ğŸ› Common Issues & Solutions

### Issue 1: "Speech recognition not supported"
**Cause**: Browser doesn't support Web Speech API
**Solution**: Use Chrome or Edge

### Issue 2: "WebSocket disconnected: Invalid authentication"
**Cause**: JWT token expired or invalid
**Solution**: Logout and login again

### Issue 3: "Failed to initialize camera streams"
**Cause**: Camera in use or not accessible
**Solution**:
- Close other apps using camera
- Check camera permissions
- Try different `CAMERA_IDS` in `.env`

### Issue 4: "Context is empty" (Phase 2)
**Cause**: No data in database
**Solution**: Normal for new installation. System will respond: "No persons detected yet"

### Issue 5: API Rate Limit (Phase 2)
**Cause**: Too many requests to Claude API
**Solution**: Wait 60 seconds, or implement caching

### Issue 6: Voice commands not working
**Possible Causes**:
1. Microphone not enabled
2. Browser doesn't support Web Speech API
3. WebSocket connection lost
4. Backend not running

**Debug Steps**:
1. Check browser console (F12) for errors
2. Check microphone permissions
3. Verify WebSocket connection (Network tab)
4. Check backend logs

---

## ğŸ“ Test Results Template

Use this to document your test results:

```
# SentinelAI Test Results

Date: _______________
Tester: _______________

## Environment
- OS: Windows ___
- Browser: _______________
- Python: _______________
- Node: _______________

## Test Results

### Phase 1 Tests
- [ ] Login & Dashboard Access
- [ ] Voice Control Activation
- [ ] Wake Word Detection
- [ ] Voice Command (Stub)
- [ ] WebSocket Reconnection
- [ ] Multi-User Isolation

### Phase 2 Tests
- [ ] Voice Command (Real AI)
- [ ] Typed Chat
- [ ] Video Clip Display
- [ ] Multiple Conversations

## Issues Found
1. _____________________________
2. _____________________________
3. _____________________________

## Performance Notes
- Wake word latency: _______ seconds
- AI response time: _______ seconds
- WebSocket reconnection: _______ seconds

## Overall Status
- [ ] All tests passed
- [ ] Minor issues found (document above)
- [ ] Critical issues found (document above)
```

---

## ğŸ¯ Success Criteria

**Phase 1 is successful if**:
- âœ… Voice control activates with microphone click
- âœ… "Hey Sentinel" is detected reliably (>80% of attempts)
- âœ… Voice commands sent to backend
- âœ… Stub responses appear in chat
- âœ… WebSocket auto-reconnects on disconnect

**Phase 2 is successful if**:
- âœ… Real AI responses from Claude API
- âœ… Responses are contextually relevant
- âœ… Video clips display (if data exists)
- âœ… Both voice and typed chat work
- âœ… Multiple conversations tracked correctly

---

## ğŸ”§ Quick Troubleshooting Commands

**Check if backend is running**:
```bash
curl http://localhost:8000/
```
Expected: `{"status":"ok","service":"SentinelAI API"}`

**Check if frontend is running**:
Open: `http://localhost:5173`

**Check database**:
```bash
ls c:/Users/hratc/sentinelai/data/
```
Should show: `sentinelai.db`

**View backend logs**:
Backend terminal shows real-time logs

**View frontend errors**:
Browser â†’ F12 â†’ Console tab

---

## ğŸ“ Need Help?

If you encounter issues:
1. Check this guide's troubleshooting sections
2. Review backend logs for error messages
3. Check browser console (F12) for frontend errors
4. Verify all prerequisites are met

Happy Testing! ğŸ‰
